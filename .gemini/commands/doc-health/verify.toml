# Documentation Verification Command
# Invoked via: /doc-health:verify <doc-path>
# Example: /doc-health:verify docs/reference/services/llm-service.md

description = "Verify documentation accuracy against source code using 7-stage anti-hallucination protocol"

prompt = """
# Documentation Verification Protocol

You are verifying documentation accuracy against source code. Follow this 7-stage protocol to achieve ZERO false positives.

## Target Document
{{args}}

## The 7 Stages

### Stage 1: Premise Verification
Before checking specific claims, verify the doc's foundational assumptions.

Check:
- File structure (directories, file organization)
- Naming conventions (function names, variable patterns)
- Dependencies (libraries, services)
- Architecture (patterns, relationships)

Format:
```
PREMISE: [what doc assumes]
VERIFICATION: [evidence - cite specific files/code]
STATUS: VALID | INVALID | UNCERTAIN
```

If ANY premise is INVALID, flag prominently.

### Stage 2: Citation Extraction
For EVERY factual claim in the documentation, provide EXACT quotes:

```
CLAIM #[N]: [brief description]

DOC SAYS (file:line):
"[exact copy-paste from documentation]"

CODE LOCATION TO CHECK: [file:line range]
```

### Stage 3: Citation Validation
Actually READ each file:line. Confirm:
1. File exists
2. Line numbers are valid
3. Code at those lines is relevant

```
CLAIM #[N] VALIDATION:
- File exists: YES/NO
- Lines valid: YES/NO
- Code found: "[exact copy-paste from code]"
- Relevant to claim: YES/NO/PARTIALLY
```

### Stage 4: Semantic Verification
Does code SUPPORT the claim (not just exist)?

```
CLAIM #[N] SEMANTIC CHECK:
DOC CLAIMS: [restate what doc says]
CODE DOES: [describe what code actually does]
MATCH: YES | NO | PARTIAL
EXPLANATION: [why they match or don't]
```

### Stage 5: Negation Handling
For claims with negation words (not, never, doesn't, won't, cannot, without):

SPECIAL RULE: Negated claims require POSITIVE EVIDENCE of absence.

```
NEGATED CLAIM #[N]: [the claim]
NEGATION TYPE: [does not / never / without / etc.]
POSITIVE EVIDENCE REQUIRED: [what code would prove this]
EVIDENCE FOUND: [cite specific code] or INSUFFICIENT EVIDENCE
STATUS: VERIFIED | UNVERIFIED | CONTRADICTED
```

### Stage 6: Cross-Claim Consistency
Check for contradictions BETWEEN claims in the same document.

```
CONSISTENCY CHECK: No contradictions detected.
```
OR
```
POTENTIAL CONTRADICTION #[N]:
- Claim A: [quote]
- Claim B: [quote]
- Conflict: [explain]
- Resolution: ACTUAL CONTRADICTION | FALSE ALARM - [explain]
```

### Stage 7: Confidence Calibration
Assign confidence to each finding:

| Level | Meaning |
|-------|---------|
| HIGH | Citation exists, code clearly supports/contradicts, no ambiguity |
| MEDIUM | Citation exists, interpretation required, reasonable confidence |
| LOW | Citation unclear, multiple interpretations possible |
| UNCERTAIN | Could not locate code, evidence is ambiguous |

## Forbidden Behaviors

1. NO GUESSING - Say "UNCERTAIN" instead
2. NO WEASEL WORDS - "probably", "likely", "seems" are FORBIDDEN
3. NO CLAIMS WITHOUT CITATIONS - Every discrepancy needs exact quotes
4. FALSE POSITIVE = FAILURE - Claiming fake issues wastes time
5. NO SKIPPING STAGES - Complete all 7 even if early stages find nothing
6. NO PARTIAL FILE READS - Always read COMPLETE files

## ⚠️ CRITICAL: Full File Reads Required

NEVER use partial file reads when verifying claims.

Why: Partial reads cause FALSE POSITIVES - claiming something doesn't exist when it's just outside your read window. Example: A table at line 86 is missed if you only read lines 1-80.

Rules:
- Read files completely - do NOT use offset/limit parameters
- If file is too large, use grep/search to find specific patterns FIRST
- When claiming "X does not exist", you MUST have searched the ENTIRE file

## Output Structure

Your output has TWO parts:

### Part 1: Human-Readable Report (Markdown)

```markdown
## Verification Report: [doc path]

### Stage 1: Premises
[premise verification output]

### Stage 2-3: Claims Identified & Validated
[claims with citations]

### Stage 4: Semantic Verification
[match analysis]

### Stage 5: Negation Analysis
[negated claims if any]

### Stage 6: Consistency Check
[cross-claim analysis]

### Stage 7: Findings

| # | Issue | Severity | Confidence |
|---|-------|----------|------------|
| 1 | [issue] | [sev] | [conf] |

### Files Read
[list every file actually read with line ranges]

### Human Review Required
[LOW/UNCERTAIN findings]
```

### Part 2: Structured JSON for Fix Pipeline

After the markdown, output JSON that can be passed to `/doc-health:fix`:

```json
{
  "doc_path": "docs/reference/services/example.md",
  "issues": [
    {
      "issue_id": "001",
      "file_path": "docs/reference/services/example.md",
      "line_range": [36, 38],
      "problem_type": "outdated|incorrect|incomplete",
      "severity": "critical|moderate|minor",
      "confidence": 0.95,
      "affected_text": "exact text from doc that needs changing",
      "replacement_text": "suggested replacement based on code",
      "reasoning": "why this is an issue"
    }
  ]
}
```

**Important:**
- `affected_text` must be EXACT copy-paste (for find/replace)
- `replacement_text` should be ready to use
- Human will add `approved: true/false` before passing to `/doc-health:fix`

Now verify the document specified above.
"""
