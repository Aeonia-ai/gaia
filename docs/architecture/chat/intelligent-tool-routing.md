# Intelligent Tool Routing Architecture

**Status**: ðŸŸ¢ Production Ready  
**Last Updated**: January 2025

## Overview

The GAIA platform implements an intelligent tool routing system that optimizes response times by teaching the LLM when to use tools versus providing direct responses. This reduces unnecessary tool usage by 70-80% and improves response times from 3-5 seconds to <1 second for simple queries.

## Core Concept: Tools + Instructions

The system provides tools in two ways:
1. **Tool Definitions**: OpenAI-format function schemas that enable tool calling
2. **Tool Instructions**: Natural language guidelines on WHEN to use each tool

This dual approach creates intelligent decision-making that tool definitions alone cannot provide.

## Tool Categories

### 1. Knowledge Base Tools (`kb_tools.py`)

Six KB tools for personal knowledge management:

```python
KB_TOOLS = [
    {
        "type": "function",
        "function": {
            "name": "search_knowledge_base",
            "description": "Search the user's knowledge base...",
            "parameters": {...}
        }
    },
    # Plus: load_kos_context, read_kb_file, list_kb_directory,
    #       load_kb_context, synthesize_kb_information
]
```

### 2. Routing Tools (`UnifiedChatHandler`)

Three routing tools for specialized services:

```python
self.routing_tools = [
    # MCP Agent - File/system operations
    {
        "name": "use_mcp_agent",
        "description": "Use this ONLY when the user explicitly asks to: 
                        read/write files outside KB, run system commands..."
    },
    # Asset Service - Media generation
    {
        "name": "use_asset_service",
        "description": "Use this ONLY when the user explicitly asks to 
                        generate/create an image, 3D model, audio..."
    },
    # Multi-agent - Complex analysis
    {
        "name": "use_multiagent_orchestration",
        "description": "Use this for complex requests requiring multiple 
                        expert perspectives..."
    }
]
```

### 3. Tool Combination

```python
# In unified_chat.py, line 262:
all_tools = self.routing_tools + KB_TOOLS

# Passed to LLM:
await chat_service.chat_completion(
    messages=messages,
    tools=all_tools,  # All 9 tools available
    tool_choice={"type": "auto"},  # LLM decides
)
```

## The Intelligence Layer: Tool Instructions

### 1. Decision Guidelines

The system prompt includes explicit instructions on when NOT to use tools:

```python
"""
Direct responses (NO tools needed) for:
- Questions about information mentioned in the current conversation
- General knowledge: "What's the capital of France?" â†’ "Paris"
- Math: "What is 2+2?" â†’ "4"
- Explanations: "How does photosynthesis work?" â†’ Direct explanation
- Creative tasks: "Tell me a joke" â†’ Direct response
- Greetings: "Hello", "How are you?" â†’ Direct response
"""
```

### 2. Tool Usage Criteria

Clear criteria for when tools ARE needed:

```python
"""
Knowledge Base tools should ONLY be used when:
- Information is NOT available in conversation history AND
- User explicitly asks for stored/archived knowledge:
  * "find my notes on Y"
  * "search my documents for X"
  * "what was I working on"
  
Use MCP Agent ONLY for:
- File system operations: "read file X", "list files in directory"
- Web searches: "search the web for..."
- System commands: "run command X"
"""
```

### 3. Performance Optimization Principle

```python
"Key principles:
1. If you can answer with your knowledge, respond directly
2. Only use tools when user explicitly asks for external action
3. When uncertain, prefer direct responses - tools add latency"
```

## Request Processing Flow

### Phase 1: Context Building
```python
async def process(self, message: str, auth: dict, context: dict):
    # Build full context
    full_context = await self.build_context(auth, context)
    # Includes: user_id, conversation_id, message_count, history
```

### Phase 2: Prompt Assembly
```python
# Get persona + tools instructions
system_prompt = await self.get_routing_prompt(full_context)

# Structure:
# [PERSONA SECTION] - From database
# [TOOLS SECTION] - Usage guidelines  
# [DIRECTIVE SECTION] - If VR/AR mode
```

### Phase 3: Single LLM Decision
```python
# One LLM call with all tools available
routing_response = await chat_service.chat_completion(
    messages=messages,
    system_prompt=system_prompt,
    tools=all_tools,
    tool_choice={"type": "auto"}  # Let LLM decide
)
```

### Phase 4: Response Handling

```python
if routing_response.get("tool_calls"):
    # Execute tools
    kb_calls = [tc for tc in tool_calls if is_kb_tool(tc)]
    tool_results = await self._execute_kb_tools(kb_calls, auth)
    
    # Generate final response with results
    final_response = await chat_service.chat_completion(
        messages=messages + tool_results,
        system_prompt="Provide response based on tool results"
    )
else:
    # Direct response - no tools needed
    return routing_response
```

## Real-World Examples

### Example 1: Direct Response (No Tools)

**User**: "What is photosynthesis?"

**System Decision**:
```
Checks: "Explanations: 'How does photosynthesis work?' â†’ Direct explanation"
Result: No tools needed
Response time: <500ms
```

**Response**: "Photosynthesis is the process by which plants convert light energy..."

### Example 2: KB Tool Usage

**User**: "Search my notes for the API design patterns we discussed"

**System Decision**:
```
Checks: "User explicitly asks for stored knowledge: 'search my notes'"
Result: Use search_knowledge_base tool
Response time: 2-3 seconds
```

**Tool Call**: `search_knowledge_base("API design patterns")`
**Response**: "I found 3 documents in your knowledge base about API design patterns..."

### Example 3: Conversation Memory (No Tools)

**User**: "What was my lucky number that I told you earlier?"

**System Decision**:
```
Checks: "Questions about information mentioned in current conversation"
Checks: Conversation history first
Result: Found in message #3 - no tools needed
Response time: <500ms
```

**Response**: "You mentioned earlier that your lucky number is 7."

## Performance Metrics

### Without Intelligent Routing
- Every question triggers tool searches
- Average response time: 3-5 seconds
- Unnecessary KB searches: 80% of requests
- Poor user experience for simple queries

### With Intelligent Routing
- Tools used only when needed
- Simple queries: <500ms
- KB searches: 2-3 seconds (when needed)
- Tool usage reduced by 70-80%
- Optimal user experience

## Tool Execution Details

### KB Tool Executor (`KBToolExecutor`)

```python
class KBToolExecutor:
    def __init__(self, auth_principal: Dict[str, Any]):
        self.auth = auth_principal
        self.kb_url = KB_SERVICE_URL
    
    async def execute(self, tool_name: str, arguments: dict):
        # Make HTTP request to KB service
        async with httpx.AsyncClient() as client:
            response = await client.post(
                f"{self.kb_url}/{tool_name}",
                json=arguments,
                headers={"X-API-Key": self.auth.get("api_key")}
            )
        return response.json()
```

### Tool Result Processing

```python
# Format tool results for LLM
tool_result_content = "\n\nTool Results:\n"
for result in tool_results:
    if result['result'].get('success'):
        content = result['result']['content']
        tool_result_content += f"\n{result['tool']}:\n{content}\n"
```

## Configuration

### Tool Availability by Context

```python
# Different tools for different API versions
if context.get("api_version") == "v0.3":
    tools = KB_TOOLS + ROUTING_TOOLS + DIRECTIVE_TOOLS
elif context.get("api_version") == "v1":
    tools = KB_TOOLS + ROUTING_TOOLS
else:
    tools = KB_TOOLS  # Minimal set
```

### Custom Tool Sets

```python
# Per-persona tool configuration (future)
if persona.name == "Researcher":
    tools += RESEARCH_TOOLS
elif persona.name == "Developer":
    tools += CODING_TOOLS
```

## Best Practices

### 1. Tool Description Clarity
- Be explicit about WHEN to use the tool
- Include keywords users might say
- Provide clear parameter descriptions

### 2. Instruction Specificity
- Give concrete examples of when to use/not use
- Prioritize conversation history checks
- Emphasize latency considerations

### 3. Tool Granularity
- Each tool should have a single, clear purpose
- Avoid overlapping functionality
- Make parameter requirements obvious

## Future Enhancements

### 1. Dynamic Tool Loading
```python
# Load tools based on user's subscription/features
available_tools = await get_user_tools(user_id)
```

### 2. Tool Usage Analytics
```python
# Track which tools are used most
analytics.track_tool_usage(tool_name, user_id, success)
```

### 3. Adaptive Instructions
```python
# Adjust instructions based on usage patterns
if user_prefers_quick_responses:
    instructions += "Strongly prefer direct responses"
```

### 4. Tool Chaining
```python
# Allow tools to call other tools
search_results = await search_knowledge_base(query)
full_content = await read_kb_file(search_results[0].path)
```

## See Also
- [Chat Service Implementation](chat-service-implementation.md)
- [KB Tools Reference](../../kb/reference/kb-http-api-reference.md)
- [Intelligent Chat Routing](../../api/chat/intelligent-chat-routing.md)